[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Report - Algorithmic Project IFEBY270",
    "section": "",
    "text": "0.1 Execution\nExecute tests\nUpdate Gamut tests",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#execution",
    "href": "index.html#execution",
    "title": "Report - Algorithmic Project IFEBY270",
    "section": "",
    "text": "./run_tests # first method\nmake test_verbose # second method\npython3 -m unittest tests.&lt;test_name&gt; # for specific test\n\nmake update_gamut",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#more-tests",
    "href": "index.html#more-tests",
    "title": "Report - Algorithmic Project IFEBY270",
    "section": "0.2 More Tests",
    "text": "0.2 More Tests\nTo incorporate additional tests using unittest into src/algorithm/&lt;problem&gt;/&lt;problem&gt;.py, modify tests/&lt;problem&gt;.py.\nAll methods with a name beginning with test_ will be executed as tests.\nExecute tests with:\npython3 -m unittest tests.&lt;test_name&gt;\n\n0.2.1 Example\nTo include another Nash Equilibrium example, edit tests/nash_equilibrium.py, and add the following method to the TestNashEquilibrium class:\ndef test_example(self):\n    self.check_equilibrium(\n        A = np.array([[3, 2], [1, 4]]), \n        B = np.array([[2, 1], [3, 2]])\n    )\nExecute the test with:\npython3 -m unittest tests.nash_equilibrium",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "simplex.html",
    "href": "simplex.html",
    "title": "2  Simplex",
    "section": "",
    "text": "2.1 Introduction\nIn linear optimization, consider a problem in canonical form:\n\\(\\max\\{c^T x \\,|\\, Ax \\leq b, x \\geq 0\\}\\)\nwhere:\n- \\(x\\) is the vector of variables to be determined\n- \\(c\\) is the vector of coefficients of the objective function\n- \\(A\\) is the matrix of coefficients of the constraints\nAny problem in canonical form can be reformulated into a problem of the form:\n\\(\\max\\{c_{0} + c^T x \\,|\\, Ax + x' = b, x \\geq 0\\, x' \\geq 0\\}\\)\nThis form is known as the standard form.\nThe Simplex algorithm is a method to move from one basic solution to another while seeking to improve the objective function.\nWhen an optimal basic solution is reached, i.e. one that maximizes the objective function, the algorithm stops.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simplex</span>"
    ]
  },
  {
    "objectID": "simplex.html#introduction",
    "href": "simplex.html#introduction",
    "title": "2  Simplex",
    "section": "",
    "text": "2.1.1 Definition Basic solution and optimal basic solution\nIn the standard form below, we assume \\(b \\geq 0\\ \\). The constant \\(c_{0}\\) is introduced for technical reasons.\nIn this case, \\((x,x'​) = (0,b)\\) constitutes a basic solution of the problem, and we also refer to the variables \\(x'\\) as basic and the variables \\(x\\) as non-basic. If the problem is unbounded, it has no optimal solution, and the solution below is admissible.\n\n\n\n2.1.2 Preparation Data organization\nLet \\(n\\) be the number of non-basic variables, and \\(m\\) be the number of basic variables.\nTo perform the calculations, it is useful to organize the data in a table \\(A\\) which initially has the following form:\n\n\n\n_\n\\(c_{1}\\)\n…\n\\(c_{n}\\)\n0\n0…\n0\n\\(-c_{0}\\)\n\n\n\n\n\\(x_{n+1}\\)\n\\(a_{1,1}\\)\n…\n\\(a_{1,n}\\)\n1\n0…\n0\n\\(b_{1}\\)\n\n\n…\n…\n…\n…\n…\n……\n…\n…\n\n\n\\(x_{n+m}\\)\n\\(a_{m,1}\\)\n…\n\\(a_{m,n}\\)\n0\n0…\n1\n\\(b_{m}\\)\n\n\n\n\nOn this table, we will perform the algorithm explained in the following section. At each iteration of the algorithm, we move from one basic solution to another, each time increasing the non-basic variables (while respecting the constraints).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simplex</span>"
    ]
  },
  {
    "objectID": "simplex.html#algorithm",
    "href": "simplex.html#algorithm",
    "title": "2  Simplex",
    "section": "2.2 Algorithm",
    "text": "2.2 Algorithm\nEach iteration of the algorithm consists of three consecutive operations:\n\n2.2.1 Step 1 Pivot selection\nIn this step, an incoming variable (non-basic) and an outgoing variable (basic) are selected as follows:\n\n– We find \\(1 \\leq e \\leq n\\) such that \\(c_{e} \\geq 0\\).\n– There are two possible scenarios:\n\n\n\\(\\forall i \\in [n+1, m], a_{i,e} \\leq 0\\). In this case, the problem is unbounded and has no optimal solution.\n\nWe look for a basic variable minimizing the quantity \\(b_{i} / a_{i,e}\\). We denote it \\(x_{s}, s \\in [n+1, m]\\).\nWe know that \\(a_{s,e} &gt; 0\\) and will use this value as a pivot.\n\n\n\n\n2.2.2 Step 2 Table update\nThis is the heart of the algorithm.\nGiven \\(x_{e}\\) as the incoming variable, \\(x_{s}\\) as the outgoing variable, and \\(a_{s-n, e}\\) as the pivot, we perform the following operations and obtain a new table \\(A'\\) (in the following order):\n\n# 1) Process lines except pivot\n\n\\(\\forall i \\in [1, m+n]\\), \\(\\forall j \\in [1, m], j \\neq s-n\\), \\(a'_{j,i} \\leftarrow a_{j,i}-a_{s-n,i}*a_{j,e}/a_{s-n,e}\\)\n\n\\(\\forall j \\in [1, m], j \\neq s-n\\), \\(b'_{j} \\leftarrow b_{j}-a_{j,e}*b_{s-n}/a_{s-n,e}\\)\n\n\n# 2) Process pivot line\n\n\\(\\forall i \\in [1, m+n], a'_{s-n,i} \\leftarrow a_{s-n,i}/a_{s-n,e}\\)\n\n\\(b_{s-n} \\leftarrow b'_{s-n}/a_{s-n,e}\\)\n\n\n# 3) Process coefficients line\n\n\\(\\forall i \\in [1, m+n]\\), \\(c'_{i} \\leftarrow c_{i} - c_{e} * a'_{s-n,i}\\)\n\\(c'_{0} \\leftarrow c_{0} + c_{e} * b_{s-n}\\)\n\n\n\n2.2.3 Step 3 Solution optimality\nAfter each iteration of Step 1 and Step 2, we check whether the stop conditions have been met.\nThe program stops if:\n\n\nall coefficients \\(c_{i}\\) are negative. in this case, the basic solution associated with our matrix \\(A\\) is an optimal basic solution to our problem, and the value of our objective function as a function of this solution is equal to \\(c_{0}\\).\n\nall non-basic variables have already been output. In this case, the problem has no optimal solution, and \\((0,b)\\) is an admissible solution.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simplex</span>"
    ]
  },
  {
    "objectID": "simplex.html#code",
    "href": "simplex.html#code",
    "title": "2  Simplex",
    "section": "2.3 Code",
    "text": "2.3 Code\nTo transform a problem into equation form, and find its optimal basic solution using the Simplex algorithm:\nsimplexe = Simplexe(canonical_form)\nbasic_sol, obj_value = simplexe.execute_simplexe()\nTo print the table obtained at the end of the calculation:\nsimplexe.print_table()\n\n2.3.1 Examples\n\\(\\textbf{2.3.1.1 Bounded Problem}\\)\n\n\\(\\max 3x_{1} + x_{2} + 2x_{3}\\)\n\\(x_{1} + x_{2} + 3x_{3} \\leq 30\\)\n\\(2x_{1} + 2x_{2} + 5x_{3} \\leq 24\\)\n\\(4x_{1} + 1x_{2} + 2x_{3} \\leq 36\\)\n\\(x_{1},x_{2},x_{3} \\geq 0\\)\n\n\ncanonical_form = [\n    [3, 1, 2],\n    [1, 1, 3, 30],\n    [2, 2, 5, 24],\n    [4, 1, 2, 36]\n]\nsimplexe = Simplexe(canonical_form)\nbasic_sol, obj_value = simplexe.execute_simplexe()\n\n[✅]Optimal solution found.\n\n\n\n\nBasic Solution:  [8.0, 4.0, 0, 18.0, 0, 0]\nObjective function value:  28.0\n\n\n\nsimplexe.print_table()\n\n['0', '0', '-1/6', '0', '-1/6', '-2/3', '-28']\n['0', '0', '1/2', '1', '-1/2', '0', '18']\n['0', '1', '8/3', '0', '2/3', '-1/3', '4']\n['1', '0', '-1/6', '0', '-1/6', '1/3', '8']\n\n\n\\(\\textbf{2.3.1.2 Unbounded Problem}\\)\n\n\\(\\max x_{1} + 2x_{2}\\)\n\\(-x_{1} - x_{2} \\leq 3\\)\n\\(-2x_{1} - 3x_{2} \\leq 5\\)\n\\(x_{1},x_{2} \\geq 0\\)\n\ncanonical_form = [\n    [1, 2],\n    [-1, -1, 3],\n    [-2, -3, 5],\n]\n\nsimplexe = Simplexe(canonical_form)\nbasic_sol, obj_value = simplexe.execute_simplexe()\n\n[❌]No optimal solution found.\n\n\n\n\nBasic Solution:  [0, 0, 3, 5]\nObjective function value:  0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simplex</span>"
    ]
  },
  {
    "objectID": "nash_equilibrium.html",
    "href": "nash_equilibrium.html",
    "title": "3  Nash Equilibrium",
    "section": "",
    "text": "3.1 Introduction\nIn game theory we consider two rational agents \\(x\\) and \\(y\\) that both want to maximize their score.\nIn discrete cases, \\(x\\) has \\(m\\) possible actions, \\(y\\) has n possible actions.\nIf \\(x\\) and \\(y\\) play simultaneously, we can considers the matrices \\(A\\) and \\(B\\) of dimension \\((m,n)\\).\n\\(A_{i,j}\\) and \\(B_{i, j}\\) represents respectivily the score of \\(x\\) and \\(y\\) when \\(x\\) plays his \\(i\\)-th action and \\(y\\) his \\(j\\)-th action.\nFor convenience, we will also call player \\(x\\) as \\(a\\), and \\(y\\) as \\(b\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Nash Equilibrium</span>"
    ]
  },
  {
    "objectID": "nash_equilibrium.html#introduction",
    "href": "nash_equilibrium.html#introduction",
    "title": "3  Nash Equilibrium",
    "section": "",
    "text": "3.1.1 Definition Stochastic vector and Strategie\nLet \\(v\\) a vector. If \\(\\sum v_i = 1\\) and \\(\\forall i, v_i \\geq 0\\), \\(v\\) is a stochastic vector.\nWe call the strategy of the player \\(x\\) and \\(y\\), the stochastic vectors \\(x\\), \\(y\\) that represents the probabilty of choosing each actions. If only one coefficient of a strategy is none negative (ie. equal to one), we call it a pure strategy.\nA best strategy \\(\\overline v\\) is a strategy that maximise the gain of its player :\n\n\n\\(\\overline x \\in \\arg \\max_x x A y^t\\)\n\\(\\overline y \\in \\arg \\max_x x B y^t\\)\n\n\nPropertie :\n\nA best strategy is always of convex combination of pure strategies.\n\n\n3.1.2 Definition Zero-sum game\nZero-sum game is defined by \\(B = -A\\), which means every gain for \\(x\\) is a loss of the same amplitude to \\(y\\), and the other way around.\n\n\n3.1.3 Definition Nash equilibrium\nA nash equilibrium is a couple \\((x, y)\\) of strategies, where \\(x\\) and \\(y\\) are both best strategies.\n\n3.1.3.1 Theorem: A nash equilibrium always exists.\nRemark: If we impose strategies to be pure, the theorem doesn’t hold. (eg: paper, rock, scissor)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Nash Equilibrium</span>"
    ]
  },
  {
    "objectID": "nash_equilibrium.html#code",
    "href": "nash_equilibrium.html#code",
    "title": "3  Nash Equilibrium",
    "section": "3.2 Code",
    "text": "3.2 Code\nTo find the nash equilibrium, create a NashEquilibrium object, and solve it.\nsolution_x, solution_y = NashEquilibrium(A, B).solve()\n\n3.2.1 Examples\n\n# Paper Rock Scissor\nA = np.array([\n    [1,0,-1],\n    [0,-1,1],\n    [-1,1,0]\n])\nsolution_x, solution_y = NashEquilibrium(A, -A).solve()\n\n\n\nx: [0.33333333 0.33333333 0.33333333]\ny: [0.33333333 0.33333333 0.33333333]\n\n\n\n# Non-zero sum game\nA = np.array([[1, 2], [3, 4]]) \nB = np.array([[4, 3], [2, 1]])\nsolution_x, solution_y = NashEquilibrium(A, B).solve()\n\n\n\nx: [0. 1.]\ny: [1. 0.]\n\n\n\nA = np.array([[3, 2], [1, 4]]) \nB = np.array([[2, 1], [3, 2]])\nsolution_x, solution_y = NashEquilibrium(A, B).solve()\n\n\n\nx: [1. 0.]\ny: [1. 0.]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Nash Equilibrium</span>"
    ]
  },
  {
    "objectID": "nash_equilibrium.html#modelization",
    "href": "nash_equilibrium.html#modelization",
    "title": "3  Nash Equilibrium",
    "section": "3.3 Modelization",
    "text": "3.3 Modelization\nWe solve this problem using pulp with mixted linear programming (linear + discrete).\n\n3.3.1 Variables :\n\n\n\n\n\n\n\n\n\nVariable\nPlayer a\nPlayer b\nDomain\n\n\n\n\nStrategies\n\\(x_{a1}, \\dots, x_{am}\\)\n\\(x_{b1}, \\dots, x_{bn}\\)\n\\([0,1]\\)\n\n\nStrategies supports\n\\(s_{a1}, \\dots s_{am}\\)\n\\(s_{b1}, \\dots, s_{bn}\\)\n\\(\\{0, 1\\}\\)\n\n\nRegrets\n\\(r_{a1}, \\dots, r_{am}\\)\n\\(r_{b1}, \\dots r_{bn}\\)\n\\([0, M]\\)\n\n\nPotential Gain\npotential_gain_a\npotential_gain_b\n\\([LG, HG]\\)\n\n\nMax Gain (scalar)\nmax_gain_a\nmax_gain_b\n\\([LG, HG]\\)\n\n\n\nM represents respectively the max regret for \\(a\\) and \\(b\\).\n\\(M_a := \\max A_{ij} - \\min A_{ij}\\)   \\(M_b := \\max B_{ij} - \\min B_{ij}\\)\nHG represents respectively the highest gain for \\(a\\) and \\(b\\).\n\\(HG_a := \\max A_{ij}\\)   \\(HG_b := \\max B_{ij}\\)\nLG represents respectively the lowest gain for \\(a\\) and \\(b\\).\n\\(LG_a := \\min A_{ij}\\)   \\(LG_b := \\min B_{ij}\\)\n\n\n3.3.2 Constraints\n\n3.3.2.1 [Eq Constraint] Stochastic vectors\n\\(\\sum x_{ai} = 1\\)\n\\(\\sum x_{bi} = 1\\)\n\n\n3.3.2.2 [Eq Constraint] Potential gain\npotential_gain_a \\(= A y^t\\)\npotential_gain_b \\(= x B\\)\n\n\n3.3.2.3 [Constraint] Max gain\n\\(\\forall i\\) max_gain_a \\(\\geq\\) potential_gain_a\\(_i\\)\n\\(\\forall j\\) max_gain_b \\(\\geq\\) potential_gain_b\\(_j\\)\n\n\n3.3.2.4 [Eq Constraint] Risk\n\\(\\vec{r_a} =\\) potential_gain_a \\(-\\) max_gain_a\n\\(\\vec{r_b} =\\) potential_gain_b \\(-\\) max_gain_b\n\n\n3.3.2.5 [Constraint] Best strategy constraint\n\\(\\forall i :\\quad\\) \\(x_{ai} \\leq s_{ai} \\qquad\\) \\(r_{ai} \\leq (1 - s_{ai}) \\times M_a\\)\n\\(\\forall j :\\quad\\) \\(x_{bj} \\leq s_{bi} \\qquad\\) \\(r_{bj} \\leq (1 - s_{bj}) \\times M_b\\)\n\n\n\n3.3.3 Objective function :\nMinimize : \\(\\sum r_{ai} + \\sum r_{bi}\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Nash Equilibrium</span>"
    ]
  },
  {
    "objectID": "knapsac.html",
    "href": "knapsac.html",
    "title": "4  KnapSac",
    "section": "",
    "text": "4.1 Introduction\nIn integer linear optimization, we consider a weight capacity for a bag, along with lists of item weights and values The goal of the Knapsack problem is to maximize the value of items placed in the bag without exceeding its weight capacity.\nMore formally : let \\(b \\in \\Bbb N, w_{1},...,w_{n} \\in \\Bbb N^n, v_{1},...,v_{n} \\in \\Bbb N^n\\)\nWe want to determine \\(\\max_i \\{\\sum_{i=1}^{n} v_{i}x_{i}\\,|\\,\\sum_{i=1}^{n} w_{i}x_{i} &lt; b, x_{i} \\in \\{0,1\\}, i = 1,..,n\\}\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>KnapSac</span>"
    ]
  },
  {
    "objectID": "knapsac.html#algorithm",
    "href": "knapsac.html#algorithm",
    "title": "4  KnapSac",
    "section": "4.2 Algorithm",
    "text": "4.2 Algorithm\n\n4.2.1 Upper bound\n    sort the items of the bag by value/weight\n    upper_bound = 0\n    weight_available = weight capacity of the bag\n    for each element in the bag:\n        if element weight &gt; weight available:\n            return upper_bound + element value * weight_available/element weight\n        else:\n            weight_available -= element weight\n            upper_bound += element value\n\n\n4.2.2 Lower bound\n    sort the items of the bag by value/weight\n    upper_bound = 0\n    weight_available = weight capacity of the bag\n    for each element in the bag:\n        if element weight &lt; weight available:\n            weight_available -= element weight\n            upper_bound += element value\n    return lower_bound\n\n\n4.2.3 Branch and bound\n    if there there are no items in the bag return 0\n    if upper_bound == lower_bound return upper_bound\n    if weight_capacity of the bag &gt;= weight of the first item in the bag\n        value1 = value of the first item in the bag + branch and bound on the bag\n        (weight_capacity - weight of the first item, items values[1:], items weights[1:])\n        if value1 == upper_bound return upper_bound\n    value2 branch and bound on the bag wihtouth the first item\n    return the max between value1 and value2\n\n\n4.2.4 Dynamic programming\n    S = [0,0]\n    for each element int the bag:\n        for each pair in S:\n            if(element weight + pair weight &lt; weight capacity of the bag):\n                add element + pair to S\n        delete redundant elements\n    return the max of the values in S\n\n\n4.2.5 Dynamic programming with adaptative scale\n    S = [0,0]\n    for each element int the bag:\n        for each pair in S:\n            if(element weight + pair weight &lt; weight capacity of the bag):\n                add element value/mu + pair value,element weight + pair weight to S\n        delete redundant elements\n    return the max of the values in S",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>KnapSac</span>"
    ]
  },
  {
    "objectID": "knapsac.html#code",
    "href": "knapsac.html#code",
    "title": "4  KnapSac",
    "section": "4.3 Code",
    "text": "4.3 Code\nTo find the solution to the KnapSack problem, create a KnapSack :\nKnapSack(weight_capacity,array of items weight, array of items value)\nThen choose a solving algorithm between :\n\nlower_bound (gives you a lower bound to the knapsack solution)\nupper_bound (gives you an upper bound to the knapsack solution)\nsolve_branch_and_bound (gives you the exact solution to the knapsack)\nsolve_dynamic_prog (gives you the exact solution to the knapsack)\nsolve_dynamic_prog_scale_change (gives you a lower bound very close to the solution for large Knapsack problems)\n\n\n4.3.1 Examples\n\nks = KnapSack(3,[1,1,1,2],[3,2,1,1])\n\n\n\nks.lower_bound() : 6\nks.upper bound() : 6.0\nks.solve_branch_and_bound() : 6\nks.solve_dynamic_prog() : 6\nks.solve_dynamic_prog_scale_change() : 4\n\n\nYou can make solve_dynamic_prog_scale_change run faster and use less memory by passing a larger mu as parameter\n\n\nks = KnapSack(3,[1,1,1,2],[8,7,3,1])\n\n\n\nks.lower_bound() : 18\nks.upper bound() : 18.0\nks.solve_branch_and_bound() : 18\nks.solve_dynamic_prog() : 18\nks.solve_dynamic_prog_scale_change() : 16\n\n\nTests with benchmark\n\nTestKnapSack.benchmark_time(ks)\n\nTimes\n    Lower Bound       : 0.000007 seconds\n    Upper Bound       : 0.000013 seconds\n    Dynamic           : 0.000019 seconds\n    Branch and Bound  : 0.000019 seconds\n    Dynamic Adaptative: 0.000023 seconds\n\n\n\nTestKnapSack.benchmark_precision(ks)\n\nResults\n    Dynamic            : 18, 100% of the solution , or 0 away from the solution\n    Branch and Bound   : 18, 100% of the solution , or 0 away from the solution\n    Upper Bound        : 18.0, 100% of the solution , or 0.0 away from the solution\n    Lower Bound        : 18, 100% of the solution , or 0 away from the solution\n    Dynamic Adaptative : 16, 89% of the solution , or -2 away from the solution",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>KnapSac</span>"
    ]
  },
  {
    "objectID": "subset_sum.html",
    "href": "subset_sum.html",
    "title": "5  SubSet Sum",
    "section": "",
    "text": "5.1 Introduction\nGiven a set of integers \\(S\\) and an integer \\(M\\), we want to find the biggest subset sum of \\(S\\) such that the sum of its elements does not exceed \\(M\\).\nThe associated decision problem is to find a subset sum that is strictly equal to \\(M\\), the existence of such a set is known to be NP-Hard.\nPerhaps, there exist two heuristics for the above problem: LLL and a dynamic programming approach.\nRemark : the general SubSet Sum problem allows \\(S\\) to be a MultiSet.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SubSet Sum</span>"
    ]
  },
  {
    "objectID": "subset_sum.html#code",
    "href": "subset_sum.html#code",
    "title": "5  SubSet Sum",
    "section": "5.2 Code",
    "text": "5.2 Code\nLet \\(S\\) be a python set of integers and \\(M\\) the target value.\nS = set(&lt;values&gt;)\nM = &lt;target_value&gt;\nTo find a solution to the subset sum problem, create a subset and solve it.\nproblem = SubSet(S, M)\ndynamic_solution = problem.solve_dynamic_prog()\nLLL_solution = problem.solve_LLL()\n\nDynamic\n\nsolve_dynamic_prog returns a couple (target, chosen elemements), as if there is no solution to the problem, it will give the closest to the target.\n\n\nLLL\n\nsolve_LLL returns a vector corresponding to the chosen elements\n\n\nAlternative constructors :\n\nConcatenantion :\n\nSubSet(S + M)\n\nRandom example :\n\nSubSet.generate_random_low_density_subset_problem(number_of_elements, density)\nIf you dont specify parameters, the number of elements will be a random number between 0 and 20, and the density will be 0.5\n\n\n\n5.2.1 Examples\n\n5.2.1.1 LLL algorithm\nTo perform a single, precise test:\n\n\nset = SubSet([23603, 6105, 5851, 19660, 8398, 8545, 14712], 37760)\nX = set.solve_LLL()\nassert np.dot(X, [23603, 6105, 5851, 19660, 8398, 8545, 14712]) == 37760\n\n\n\nX = [0, 1, 0, 0, 1, 1, 1]\n\n\nTo parameterize set length and density, and study the algorithm’s performance:\n\n\nsolved_count = 0\nunsolved_count = 0\ntotal_density = 0\nn = 4\n\nfor i in range(1000):\n    subset_problem = SubSet.generate_random_low_density_subset_problem(n,density=0.2)\n    X = subset_problem.solve_LLL()\n    density = subset_problem.density()\n    \n    if X is not None:\n        solved_count += 1\n        total_density += density\n    else:\n        unsolved_count += 1\n\navg_density = total_density / solved_count if solved_count &gt; 0 else 0\n\n\n\nBenchmark Table: n = 4\nNumber of problems solved: 555\nNumber of problems unsolved: 445\nAverage density: 0.19783403475538835\n\n\nThe test above can be modified in the tests/subset_sum.py file.\n\n\n5.2.1.2 Dynamic programming\n\nproblem = SubSet([23603, 6105, 5851, 19660, 8398, 8545, 14712], 37760)\n\ndynamic_solution = problem.solve_dynamic_prog()\n\n\n\nDynamic solution : (37760, [6105, 8398, 8545, 14712])",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SubSet Sum</span>"
    ]
  }
]